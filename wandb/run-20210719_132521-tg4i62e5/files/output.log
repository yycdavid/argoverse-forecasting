Training begins ...
2021-07-19 13:25:39.460541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-07-19 13:25:39.461521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:86:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-07-19 13:25:39.461689: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jasonyma/.mujoco/mujoco200/bin:/home/jasonyma/.mujoco/mujoco200/bin
2021-07-19 13:25:39.464001: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2021-07-19 13:25:39.465965: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-07-19 13:25:39.466269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-07-19 13:25:39.469272: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-07-19 13:25:39.471510: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2021-07-19 13:25:39.471688: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/jasonyma/.mujoco/mujoco200/bin:/home/jasonyma/.mujoco/mujoco200/bin
2021-07-19 13:25:39.471701: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-07-19 13:25:39.472477: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-19 13:25:39.519397: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2400000000 Hz
2021-07-19 13:25:39.527690: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56556eb4d0e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-07-19 13:25:39.527737: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-07-19 13:25:39.527929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-19 13:25:39.527954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      
Train -- Epoch:0, loss:6.612930774688721, Rollout:30
Training epoch completed in 1.4283450524012247 mins, Total time: 1.4297884742418925 mins
Training epoch completed in 1.4000258763631186 mins, Total time: 2.82981782356898 mins
Train -- Epoch:2, loss:5.8620805740356445, Rollout:30
Training epoch completed in 1.4711554646492004 mins, Total time: 4.300974440574646 mins
Training epoch completed in 1.4214829961458841 mins, Total time: 5.722459053993225 mins
Train -- Epoch:4, loss:6.03857421875, Rollout:30
Training epoch completed in 1.4977218667666117 mins, Total time: 7.220183094342549 mins
[32mVal -- Epoch:5, loss:5.90293550491333, Rollout: 1[0m
[32mVal -- Epoch:5, loss:5.916341781616211, Rollout: 1[0m
[32mVal -- Epoch:5, loss:5.93349027633667, Rollout: 1[0m
[32mVal -- Epoch:5, loss:5.924681186676025, Rollout: 1[0m
[32mVal -- Epoch:5, loss:6.04925012588501, Rollout: 1[0m
[32mVal -- Epoch:5, loss:5.907138824462891, Rollout: 1[0m
[32mVal -- Epoch:5, loss:5.91317892074585, Rollout: 1[0m
[32mVal -- Epoch:5, loss:5.898427963256836, Rollout: 1[0m
Validation completed in 0.19136821428934733 mins, Total time: 7.411552703380584 mins
Training epoch completed in 1.4774359862009685 mins, Total time: 8.888990791638692 mins
Training epoch completed in 1.4741108934084575 mins, Total time: 10.363103350003561 mins
Train -- Epoch:7, loss:5.856983184814453, Rollout:30
Training epoch completed in 1.5207568605740864 mins, Total time: 11.883862785498302 mins
Training epoch completed in 1.645058516661326 mins, Total time: 13.528924651940663 mins
Train -- Epoch:9, loss:5.8490095138549805, Rollout:30
Training epoch completed in 1.4402849634488424 mins, Total time: 14.969210855166118 mins
[32mVal -- Epoch:10, loss:5.899646282196045, Rollout: 1[0m
[32mVal -- Epoch:10, loss:5.91562032699585, Rollout: 1[0m
[32mVal -- Epoch:10, loss:5.925723552703857, Rollout: 1[0m
[32mVal -- Epoch:10, loss:5.921840667724609, Rollout: 1[0m
[32mVal -- Epoch:10, loss:6.06028938293457, Rollout: 1[0m
[32mVal -- Epoch:10, loss:5.902459621429443, Rollout: 1[0m
[32mVal -- Epoch:10, loss:5.9110846519470215, Rollout: 1[0m
[32mVal -- Epoch:10, loss:5.894468307495117, Rollout: 1[0m
Validation completed in 0.22467652161916096 mins, Total time: 15.193889403343201 mins
Training epoch completed in 1.4005552212397256 mins, Total time: 16.594445260365806 mins
Training epoch completed in 1.4403051416079202 mins, Total time: 18.03475216229757 mins
Train -- Epoch:12, loss:5.866050720214844, Rollout:30
Training epoch completed in 1.4172075668970743 mins, Total time: 19.45196100870768 mins
Training epoch completed in 1.377609101931254 mins, Total time: 20.829571346441906 mins
Train -- Epoch:14, loss:5.881005764007568, Rollout:30
Training epoch completed in 1.4319618066151938 mins, Total time: 22.261534504095714 mins
[32mVal -- Epoch:15, loss:5.896146774291992, Rollout: 1[0m
[32mVal -- Epoch:15, loss:5.909096717834473, Rollout: 1[0m
[32mVal -- Epoch:15, loss:5.924071788787842, Rollout: 1[0m
[32mVal -- Epoch:15, loss:5.916251182556152, Rollout: 1[0m
[32mVal -- Epoch:15, loss:6.053854942321777, Rollout: 1[0m
[32mVal -- Epoch:15, loss:5.896676063537598, Rollout: 1[0m
[32mVal -- Epoch:15, loss:5.906276702880859, Rollout: 1[0m
[32mVal -- Epoch:15, loss:5.890384674072266, Rollout: 1[0m
Validation completed in 0.2428861935933431 mins, Total time: 22.504423213005065 mins
Training epoch completed in 1.4395851810773215 mins, Total time: 23.944009153048196 mins
Training epoch completed in 1.4584175626436868 mins, Total time: 25.40242879788081 mins
Train -- Epoch:17, loss:5.812867164611816, Rollout:30
Training epoch completed in 1.4165523370107016 mins, Total time: 26.818982402483623 mins
Training epoch completed in 1.4532085537910462 mins, Total time: 28.27219302256902 mins
Train -- Epoch:19, loss:5.926120281219482, Rollout:30
Training epoch completed in 1.4109330415725707 mins, Total time: 29.683127999305725 mins
[32mVal -- Epoch:20, loss:5.8925323486328125, Rollout: 1[0m
[32mVal -- Epoch:20, loss:5.902979373931885, Rollout: 1[0m
[32mVal -- Epoch:20, loss:5.926462173461914, Rollout: 1[0m
[32mVal -- Epoch:20, loss:5.925941467285156, Rollout: 1[0m
[32mVal -- Epoch:20, loss:6.062506675720215, Rollout: 1[0m
[32mVal -- Epoch:20, loss:5.894983768463135, Rollout: 1[0m
[32mVal -- Epoch:20, loss:5.915642738342285, Rollout: 1[0m
[32mVal -- Epoch:20, loss:5.893433094024658, Rollout: 1[0m
Validation completed in 0.24196524222691854 mins, Total time: 29.925094668070475 mins
Training epoch completed in 1.3917453010876975 mins, Total time: 31.316840736071267 mins
Training epoch completed in 1.3927950143814087 mins, Total time: 32.709637530644734 mins
Train -- Epoch:22, loss:5.875155925750732, Rollout:30
Training epoch completed in 1.4142706751823426 mins, Total time: 34.123910224437715 mins
Training epoch completed in 1.3400736729303995 mins, Total time: 35.463985137144725 mins
Train -- Epoch:24, loss:5.802846431732178, Rollout:30
Training epoch completed in 1.452026609579722 mins, Total time: 36.916013431549075 mins
[32mVal -- Epoch:25, loss:5.89033842086792, Rollout: 1[0m
[32mVal -- Epoch:25, loss:5.907281398773193, Rollout: 1[0m
[32mVal -- Epoch:25, loss:5.930789947509766, Rollout: 1[0m
[32mVal -- Epoch:25, loss:5.915546417236328, Rollout: 1[0m
[32mVal -- Epoch:25, loss:6.050042629241943, Rollout: 1[0m
[32mVal -- Epoch:25, loss:5.895448684692383, Rollout: 1[0m
[32mVal -- Epoch:25, loss:5.901137351989746, Rollout: 1[0m
[32mVal -- Epoch:25, loss:5.892104148864746, Rollout: 1[0m
Validation completed in 0.25231643120447794 mins, Total time: 37.16833086411158 mins
Training epoch completed in 1.3617813309033713 mins, Total time: 38.53011326392492 mins
Training epoch completed in 1.4291547775268554 mins, Total time: 39.9592697819074 mins
Train -- Epoch:27, loss:5.902740955352783, Rollout:30
Training epoch completed in 1.4247002085049947 mins, Total time: 41.38397228717804 mins
Training epoch completed in 1.3970083634058634 mins, Total time: 42.78098254998525 mins
Train -- Epoch:29, loss:5.96234130859375, Rollout:30
Training epoch completed in 1.3738351702690124 mins, Total time: 44.154819651444754 mins
[32mVal -- Epoch:30, loss:5.8837432861328125, Rollout: 1[0m
[32mVal -- Epoch:30, loss:5.901706218719482, Rollout: 1[0m
[32mVal -- Epoch:30, loss:5.9188385009765625, Rollout: 1[0m
[32mVal -- Epoch:30, loss:5.905064105987549, Rollout: 1[0m
[32mVal -- Epoch:30, loss:6.043582439422607, Rollout: 1[0m
[32mVal -- Epoch:30, loss:5.887580394744873, Rollout: 1[0m
[32mVal -- Epoch:30, loss:5.8937506675720215, Rollout: 1[0m
[32mVal -- Epoch:30, loss:5.885072231292725, Rollout: 1[0m
Validation completed in 0.20045253833134968 mins, Total time: 44.35527330636978 mins
Training epoch completed in 1.3983500758806864 mins, Total time: 45.75362456242244 mins
Training epoch completed in 1.392855707804362 mins, Total time: 47.14648254315058 mins
Train -- Epoch:32, loss:5.85107946395874, Rollout:30
Training epoch completed in 1.4011834383010864 mins, Total time: 48.54766800006231 mins
Training epoch completed in 1.4207807898521423 mins, Total time: 49.968450669447584 mins
Train -- Epoch:34, loss:5.821709156036377, Rollout:30
Training epoch completed in 1.410701855023702 mins, Total time: 51.37915468613307 mins
[32mVal -- Epoch:35, loss:5.878081798553467, Rollout: 1[0m
[32mVal -- Epoch:35, loss:5.895847320556641, Rollout: 1[0m
[32mVal -- Epoch:35, loss:5.921324729919434, Rollout: 1[0m
[32mVal -- Epoch:35, loss:5.90821647644043, Rollout: 1[0m
[32mVal -- Epoch:35, loss:6.041101932525635, Rollout: 1[0m
[32mVal -- Epoch:35, loss:5.883162975311279, Rollout: 1[0m
[32mVal -- Epoch:35, loss:5.893008232116699, Rollout: 1[0m
[32mVal -- Epoch:35, loss:5.88194465637207, Rollout: 1[0m
Validation completed in 0.20402105649312338 mins, Total time: 51.5831772963206 mins
Training epoch completed in 1.3786752541859946 mins, Total time: 52.961855590343475 mins
Training epoch completed in 1.3455195506413777 mins, Total time: 54.30737608671188 mins
Train -- Epoch:37, loss:5.872896194458008, Rollout:30
Training epoch completed in 1.4058936317761739 mins, Total time: 55.71327168941498 mins
Training epoch completed in 1.413921558856964 mins, Total time: 57.12719521919886 mins
Train -- Epoch:39, loss:5.884846210479736, Rollout:30
Training epoch completed in 1.390479282538096 mins, Total time: 58.51767667134603 mins
[32mVal -- Epoch:40, loss:5.885119438171387, Rollout: 1[0m
[32mVal -- Epoch:40, loss:5.89979362487793, Rollout: 1[0m
[32mVal -- Epoch:40, loss:5.917538642883301, Rollout: 1[0m
[32mVal -- Epoch:40, loss:5.903390407562256, Rollout: 1[0m
[32mVal -- Epoch:40, loss:6.035205364227295, Rollout: 1[0m
[32mVal -- Epoch:40, loss:5.883255481719971, Rollout: 1[0m
[32mVal -- Epoch:40, loss:5.890442371368408, Rollout: 1[0m
[32mVal -- Epoch:40, loss:5.886911392211914, Rollout: 1[0m
Validation completed in 0.23420693079630533 mins, Total time: 58.75188551346461 mins
Training epoch completed in 1.365745691458384 mins, Total time: 60.117631967862444 mins
Training epoch completed in 1.3961418509483337 mins, Total time: 61.513775845368706 mins
Train -- Epoch:42, loss:5.906045436859131, Rollout:30
Training epoch completed in 1.3453165372212728 mins, Total time: 62.8590935587883 mins
Training epoch completed in 1.4021020611127217 mins, Total time: 64.26119755109151 mins
Train -- Epoch:44, loss:5.854804992675781, Rollout:30
Training epoch completed in 1.405720873673757 mins, Total time: 65.66691967248917 mins
[32mVal -- Epoch:45, loss:5.879075527191162, Rollout: 1[0m
[32mVal -- Epoch:45, loss:5.902065277099609, Rollout: 1[0m
[32mVal -- Epoch:45, loss:5.914399147033691, Rollout: 1[0m
[32mVal -- Epoch:45, loss:5.901440620422363, Rollout: 1[0m
[32mVal -- Epoch:45, loss:6.037997245788574, Rollout: 1[0m
[32mVal -- Epoch:45, loss:5.880685806274414, Rollout: 1[0m
[32mVal -- Epoch:45, loss:5.894322872161865, Rollout: 1[0m
[32mVal -- Epoch:45, loss:5.881850242614746, Rollout: 1[0m
Validation completed in 0.1911575158437093 mins, Total time: 65.85807897249857 mins
Training epoch completed in 1.4305078466733296 mins, Total time: 67.28858892122905 mins
Training epoch completed in 1.3780986030896505 mins, Total time: 68.66668869654337 mins
Train -- Epoch:47, loss:5.877791881561279, Rollout:30
Training epoch completed in 1.3392219344774883 mins, Total time: 70.00591185887654 mins
Training epoch completed in 1.4043203949928285 mins, Total time: 71.41023389498393 mins
Train -- Epoch:49, loss:5.837665557861328, Rollout:30
Training epoch completed in 1.2845934589703878 mins, Total time: 72.69482950766881 mins
[32mVal -- Epoch:50, loss:5.880880355834961, Rollout: 1[0m
[32mVal -- Epoch:50, loss:5.902695655822754, Rollout: 1[0m
[32mVal -- Epoch:50, loss:5.917038440704346, Rollout: 1[0m
[32mVal -- Epoch:50, loss:5.9084577560424805, Rollout: 1[0m
[32mVal -- Epoch:50, loss:6.038655757904053, Rollout: 1[0m
[32mVal -- Epoch:50, loss:5.889995098114014, Rollout: 1[0m
[32mVal -- Epoch:50, loss:5.903064250946045, Rollout: 1[0m
[32mVal -- Epoch:50, loss:5.883107662200928, Rollout: 1[0m
Validation completed in 0.22087730964024863 mins, Total time: 72.9157088001569 mins
Training epoch completed in 1.3790398399035135 mins, Total time: 74.29475087324778 mins
Training epoch completed in 1.3698137521743774 mins, Total time: 75.66456651687622 mins
Train -- Epoch:52, loss:5.890509605407715, Rollout:30
Training epoch completed in 1.384838350613912 mins, Total time: 77.04940681060155 mins
Training epoch completed in 1.4144856929779053 mins, Total time: 78.4638944586118 mins
Train -- Epoch:54, loss:5.849857330322266, Rollout:30
Training epoch completed in 1.383937418460846 mins, Total time: 79.8478340268135 mins
[32mVal -- Epoch:55, loss:5.8833208084106445, Rollout: 1[0m
[32mVal -- Epoch:55, loss:5.902242183685303, Rollout: 1[0m
[32mVal -- Epoch:55, loss:5.92726469039917, Rollout: 1[0m
[32mVal -- Epoch:55, loss:5.915324687957764, Rollout: 1[0m
[32mVal -- Epoch:55, loss:6.0475687980651855, Rollout: 1[0m
[32mVal -- Epoch:55, loss:5.8908491134643555, Rollout: 1[0m
[32mVal -- Epoch:55, loss:5.900362491607666, Rollout: 1[0m
[32mVal -- Epoch:55, loss:5.88949728012085, Rollout: 1[0m
Validation completed in 0.22607851425806683 mins, Total time: 80.07391440471014 mins
Training epoch completed in 1.4030512809753417 mins, Total time: 81.47696758111319 mins
Training epoch completed in 1.3345639824867248 mins, Total time: 82.81153358221054 mins
Train -- Epoch:57, loss:5.851770401000977, Rollout:30
Training epoch completed in 1.3591043949127197 mins, Total time: 84.17063907782237 mins
Training epoch completed in 1.418669601281484 mins, Total time: 85.58931053876877 mins
Train -- Epoch:59, loss:5.827085018157959, Rollout:30
Training epoch completed in 1.3230357408523559 mins, Total time: 86.9123479604721 mins
[32mVal -- Epoch:60, loss:5.884167671203613, Rollout: 1[0m
[32mVal -- Epoch:60, loss:5.899598121643066, Rollout: 1[0m
[32mVal -- Epoch:60, loss:5.921139240264893, Rollout: 1[0m
[32mVal -- Epoch:60, loss:5.910747528076172, Rollout: 1[0m
[32mVal -- Epoch:60, loss:6.0469231605529785, Rollout: 1[0m
[32mVal -- Epoch:60, loss:5.884387493133545, Rollout: 1[0m
[32mVal -- Epoch:60, loss:5.895449638366699, Rollout: 1[0m
[32mVal -- Epoch:60, loss:5.887913703918457, Rollout: 1[0m
Validation completed in 0.19390199979146322 mins, Total time: 87.10625092983246 mins
Training epoch completed in 1.299507490793864 mins, Total time: 88.40576071341833 mins
Training epoch completed in 1.3701367815335592 mins, Total time: 89.77589939832687 mins
Train -- Epoch:62, loss:5.835980415344238, Rollout:30
Training epoch completed in 1.325473682085673 mins, Total time: 91.1013742963473 mins
Training epoch completed in 1.3737072587013244 mins, Total time: 92.47508330742518 mins
Train -- Epoch:64, loss:5.8725786209106445, Rollout:30
Training epoch completed in 1.4068989396095275 mins, Total time: 93.88198397954305 mins
[32mVal -- Epoch:65, loss:5.881138324737549, Rollout: 1[0m
[32mVal -- Epoch:65, loss:5.8997273445129395, Rollout: 1[0m
[32mVal -- Epoch:65, loss:5.919622421264648, Rollout: 1[0m
[32mVal -- Epoch:65, loss:5.912266731262207, Rollout: 1[0m
[32mVal -- Epoch:65, loss:6.0477118492126465, Rollout: 1[0m
[32mVal -- Epoch:65, loss:5.885531902313232, Rollout: 1[0m
[32mVal -- Epoch:65, loss:5.8981828689575195, Rollout: 1[0m
[32mVal -- Epoch:65, loss:5.889005661010742, Rollout: 1[0m
Validation completed in 0.2108890652656555 mins, Total time: 94.09287421703338 mins
Training epoch completed in 1.3687282085418702 mins, Total time: 95.46160386800766 mins
Train -- Epoch:66, loss:5.897435665130615, Rollout:30
Training epoch completed in 1.342022430896759 mins, Total time: 96.80362728436788 mins
Training epoch completed in 1.3269054452578226 mins, Total time: 98.13053526480992 mins
Training epoch completed in 1.346410071849823 mins, Total time: 99.4769472638766 mins
Train -- Epoch:69, loss:5.837235927581787, Rollout:30
Training epoch completed in 1.3690906127293905 mins, Total time: 100.84604174296061 mins
[32mVal -- Epoch:70, loss:5.887757778167725, Rollout: 1[0m
[32mVal -- Epoch:70, loss:5.905785083770752, Rollout: 1[0m
[32mVal -- Epoch:70, loss:5.926784038543701, Rollout: 1[0m
[32mVal -- Epoch:70, loss:5.915435314178467, Rollout: 1[0m
[32mVal -- Epoch:70, loss:6.055312633514404, Rollout: 1[0m
[32mVal -- Epoch:70, loss:5.89534330368042, Rollout: 1[0m
[32mVal -- Epoch:70, loss:5.902845859527588, Rollout: 1[0m
[32mVal -- Epoch:70, loss:5.89713191986084, Rollout: 1[0m
Validation completed in 0.20082640250523884 mins, Total time: 101.04686912298203 mins
Training epoch completed in 1.3548293670018514 mins, Total time: 102.4016997297605 mins
Train -- Epoch:71, loss:5.907020568847656, Rollout:30
Training epoch completed in 1.3457001407941183 mins, Total time: 103.7474017659823 mins
Training epoch completed in 1.3735137740770975 mins, Total time: 105.1209165096283 mins
Training epoch completed in 1.3566994984944662 mins, Total time: 106.47761795520782 mins
Train -- Epoch:74, loss:5.891435146331787, Rollout:30
Training epoch completed in 1.3652787367502848 mins, Total time: 107.84290050665537 mins
[32mVal -- Epoch:75, loss:5.887839317321777, Rollout: 1[0m
[32mVal -- Epoch:75, loss:5.905641555786133, Rollout: 1[0m
[32mVal -- Epoch:75, loss:5.92626953125, Rollout: 1[0m
[32mVal -- Epoch:75, loss:5.917303085327148, Rollout: 1[0m
[32mVal -- Epoch:75, loss:6.050655841827393, Rollout: 1[0m
[32mVal -- Epoch:75, loss:5.888454914093018, Rollout: 1[0m
[32mVal -- Epoch:75, loss:5.901514530181885, Rollout: 1[0m
[32mVal -- Epoch:75, loss:5.892611503601074, Rollout: 1[0m
Validation completed in 0.19143649339675903 mins, Total time: 108.03433792193731 mins
Training epoch completed in 1.3625142455101014 mins, Total time: 109.39685325225194 mins
Train -- Epoch:76, loss:5.888850688934326, Rollout:30
Training epoch completed in 1.291066551208496 mins, Total time: 110.687921555837 mins
Training epoch completed in 1.3423285881678264 mins, Total time: 112.03025099436442 mins
Training epoch completed in 1.417585305372874 mins, Total time: 113.44784107208253 mins
Train -- Epoch:79, loss:5.857695579528809, Rollout:30
Training epoch completed in 1.3763690670331319 mins, Total time: 114.82421199480693 mins
[32mVal -- Epoch:80, loss:5.8855133056640625, Rollout: 1[0m
[32mVal -- Epoch:80, loss:5.904867649078369, Rollout: 1[0m
[32mVal -- Epoch:80, loss:5.923235893249512, Rollout: 1[0m
[32mVal -- Epoch:80, loss:5.913850784301758, Rollout: 1[0m
[32mVal -- Epoch:80, loss:6.051079273223877, Rollout: 1[0m
[32mVal -- Epoch:80, loss:5.886609077453613, Rollout: 1[0m
[32mVal -- Epoch:80, loss:5.902021408081055, Rollout: 1[0m
[32mVal -- Epoch:80, loss:5.891617298126221, Rollout: 1[0m
Validation completed in 0.19436662594477336 mins, Total time: 115.01857959429422 mins
Training epoch completed in 1.4370571374893188 mins, Total time: 116.45563745101293 mins
Train -- Epoch:81, loss:5.877002716064453, Rollout:30
Training epoch completed in 1.3695897062619526 mins, Total time: 117.8252290725708 mins
Training epoch completed in 1.345947813987732 mins, Total time: 119.17117768923441 mins
Training epoch completed in 1.3816553950309753 mins, Total time: 120.55283431609472 mins
Train -- Epoch:84, loss:5.833273887634277, Rollout:30
Training epoch completed in 1.3147321740786235 mins, Total time: 121.8675707300504 mins
[32mVal -- Epoch:85, loss:5.885491847991943, Rollout: 1[0m
[32mVal -- Epoch:85, loss:5.9019293785095215, Rollout: 1[0m
[32mVal -- Epoch:85, loss:5.92645263671875, Rollout: 1[0m
[32mVal -- Epoch:85, loss:5.913715362548828, Rollout: 1[0m
[32mVal -- Epoch:85, loss:6.049860000610352, Rollout: 1[0m
[32mVal -- Epoch:85, loss:5.88568115234375, Rollout: 1[0m
[32mVal -- Epoch:85, loss:5.899328231811523, Rollout: 1[0m
[32mVal -- Epoch:85, loss:5.89133882522583, Rollout: 1[0m
Validation completed in 0.19434213638305664 mins, Total time: 122.06191463470459 mins
Training epoch completed in 1.4226964076360067 mins, Total time: 123.48461175362269 mins
Train -- Epoch:86, loss:5.83523416519165, Rollout:30
Training epoch completed in 1.3058447043100994 mins, Total time: 124.79045821030935 mins
Training epoch completed in 1.4603740374247234 mins, Total time: 126.25083372990291 mins
Training epoch completed in 1.3501423517862956 mins, Total time: 127.60097722609838 mins
Train -- Epoch:89, loss:5.857448577880859, Rollout:30
Training epoch completed in 1.3626792947451274 mins, Total time: 128.96365851561228 mins
[32mVal -- Epoch:90, loss:5.884150981903076, Rollout: 1[0m
[32mVal -- Epoch:90, loss:5.901451110839844, Rollout: 1[0m
[32mVal -- Epoch:90, loss:5.924059867858887, Rollout: 1[0m
[32mVal -- Epoch:90, loss:5.908074378967285, Rollout: 1[0m
[32mVal -- Epoch:90, loss:6.046953201293945, Rollout: 1[0m
[32mVal -- Epoch:90, loss:5.8805131912231445, Rollout: 1[0m
[32mVal -- Epoch:90, loss:5.8971476554870605, Rollout: 1[0m
[32mVal -- Epoch:90, loss:5.889682769775391, Rollout: 1[0m
Validation completed in 0.23235950072606404 mins, Total time: 129.19601907730103 mins
Training epoch completed in 1.3346152265866598 mins, Total time: 130.53063557942707 mins
Train -- Epoch:91, loss:5.8156514167785645, Rollout:30
Training epoch completed in 1.35570338567098 mins, Total time: 131.8863406499227 mins
Training epoch completed in 1.3843702832857767 mins, Total time: 133.27071222464244 mins
Training epoch completed in 1.384795347849528 mins, Total time: 134.65550961494446 mins
Train -- Epoch:94, loss:5.880772113800049, Rollout:30
Training epoch completed in 1.4143419106801352 mins, Total time: 136.06985334157943 mins
[32mVal -- Epoch:95, loss:5.885530471801758, Rollout: 1[0m
[32mVal -- Epoch:95, loss:5.90248966217041, Rollout: 1[0m
[32mVal -- Epoch:95, loss:5.924223899841309, Rollout: 1[0m
[32mVal -- Epoch:95, loss:5.911483287811279, Rollout: 1[0m
[32mVal -- Epoch:95, loss:6.050360679626465, Rollout: 1[0m
[32mVal -- Epoch:95, loss:5.879203796386719, Rollout: 1[0m
[32mVal -- Epoch:95, loss:5.901500225067139, Rollout: 1[0m
[32mVal -- Epoch:95, loss:5.886801242828369, Rollout: 1[0m
Validation completed in 0.2283222754796346 mins, Total time: 136.29817739725112 mins
Training epoch completed in 1.2612236698468526 mins, Total time: 137.55940173069635 mins
Train -- Epoch:96, loss:5.888404369354248, Rollout:30
Training epoch completed in 1.3052920937538146 mins, Total time: 138.8646955450376 mins
Training epoch completed in 1.3273362835248312 mins, Total time: 140.1920336484909 mins
Training epoch completed in 1.3493379394213358 mins, Total time: 141.54137281576791 mins
Train -- Epoch:99, loss:5.855332851409912, Rollout:30
Training epoch completed in 1.3315764824549357 mins, Total time: 142.87295234998066 mins
[32mVal -- Epoch:100, loss:5.886496543884277, Rollout: 1[0m
[32mVal -- Epoch:100, loss:5.900773525238037, Rollout: 1[0m
[32mVal -- Epoch:100, loss:5.925464630126953, Rollout: 1[0m
[32mVal -- Epoch:100, loss:5.912369251251221, Rollout: 1[0m
[32mVal -- Epoch:100, loss:6.043219566345215, Rollout: 1[0m
[32mVal -- Epoch:100, loss:5.884870529174805, Rollout: 1[0m
[32mVal -- Epoch:100, loss:5.898468971252441, Rollout: 1[0m
[32mVal -- Epoch:100, loss:5.889679908752441, Rollout: 1[0m
Validation completed in 0.1895806392033895 mins, Total time: 143.06253476142882 mins
Training epoch completed in 1.3570423245429992 mins, Total time: 144.419578286012 mins
Train -- Epoch:101, loss:5.869580268859863, Rollout:30
Training epoch completed in 1.433921511967977 mins, Total time: 145.85350086291632 mins
Training epoch completed in 1.317599860827128 mins, Total time: 147.17110162178676 mins
Training epoch completed in 1.3226059158643086 mins, Total time: 148.49371078411738 mins
Train -- Epoch:104, loss:5.856260299682617, Rollout:30
Training epoch completed in 1.3408072272936502 mins, Total time: 149.83451910416287 mins
[32mVal -- Epoch:105, loss:5.8810014724731445, Rollout: 1[0m
[32mVal -- Epoch:105, loss:5.89582633972168, Rollout: 1[0m
[32mVal -- Epoch:105, loss:5.923108100891113, Rollout: 1[0m
[32mVal -- Epoch:105, loss:5.906913757324219, Rollout: 1[0m
[32mVal -- Epoch:105, loss:6.036209583282471, Rollout: 1[0m
[32mVal -- Epoch:105, loss:5.880465507507324, Rollout: 1[0m
[32mVal -- Epoch:105, loss:5.892357349395752, Rollout: 1[0m
[32mVal -- Epoch:105, loss:5.884183883666992, Rollout: 1[0m
Validation completed in 0.18791302839914958 mins, Total time: 150.02243395646414 mins
Training epoch completed in 1.3439911405245464 mins, Total time: 151.36642584005992 mins
Train -- Epoch:106, loss:5.89805793762207, Rollout:30
Training epoch completed in 1.3389882961908977 mins, Total time: 152.70541534423828 mins
Training epoch completed in 1.3209821065266927 mins, Total time: 154.02639917929966 mins
Training epoch completed in 1.3143027623494465 mins, Total time: 155.3407040754954 mins
Train -- Epoch:109, loss:5.899312973022461, Rollout:30
Training epoch completed in 1.2673044323921203 mins, Total time: 156.60801062981287 mins
[32mVal -- Epoch:110, loss:5.883782863616943, Rollout: 1[0m
[32mVal -- Epoch:110, loss:5.897657871246338, Rollout: 1[0m
[32mVal -- Epoch:110, loss:5.921628952026367, Rollout: 1[0m
[32mVal -- Epoch:110, loss:5.908782005310059, Rollout: 1[0m
[32mVal -- Epoch:110, loss:6.0389204025268555, Rollout: 1[0m
[32mVal -- Epoch:110, loss:5.880094051361084, Rollout: 1[0m
[32mVal -- Epoch:110, loss:5.895025730133057, Rollout: 1[0m
[32mVal -- Epoch:110, loss:5.885382652282715, Rollout: 1[0m
Validation completed in 0.20373821258544922 mins, Total time: 156.81174989541373 mins
Training epoch completed in 1.3405823151270548 mins, Total time: 158.15233372449876 mins
Train -- Epoch:111, loss:5.866866111755371, Rollout:30
Training epoch completed in 1.2875410636266074 mins, Total time: 159.439876973629 mins
Training epoch completed in 1.3213605841000875 mins, Total time: 160.76123962402343 mins
Training epoch completed in 1.3298914154370627 mins, Total time: 162.09113314151764 mins
Train -- Epoch:114, loss:5.814195156097412, Rollout:30
Training epoch completed in 1.4020286758740743 mins, Total time: 163.4931637406349 mins
[32mVal -- Epoch:115, loss:5.880502223968506, Rollout: 1[0m
[32mVal -- Epoch:115, loss:5.898626804351807, Rollout: 1[0m
[32mVal -- Epoch:115, loss:5.923878192901611, Rollout: 1[0m
[32mVal -- Epoch:115, loss:5.907602787017822, Rollout: 1[0m
[32mVal -- Epoch:115, loss:6.038787364959717, Rollout: 1[0m
[32mVal -- Epoch:115, loss:5.88340950012207, Rollout: 1[0m
[32mVal -- Epoch:115, loss:5.8948588371276855, Rollout: 1[0m
[32mVal -- Epoch:115, loss:5.886901378631592, Rollout: 1[0m
Validation completed in 0.1858602484067281 mins, Total time: 163.679025665919 mins
Training epoch completed in 1.353204615910848 mins, Total time: 165.03223160902658 mins
Train -- Epoch:116, loss:5.895978927612305, Rollout:30
Training epoch completed in 1.3563613653182984 mins, Total time: 166.38859486579895 mins
Training epoch completed in 1.336149513721466 mins, Total time: 167.7247463107109 mins
Training epoch completed in 1.28859885931015 mins, Total time: 169.01334734360378 mins
Train -- Epoch:119, loss:5.903841972351074, Rollout:30
Training epoch completed in 1.320396641890208 mins, Total time: 170.33374669154486 mins
[32mVal -- Epoch:120, loss:5.886191368103027, Rollout: 1[0m
[32mVal -- Epoch:120, loss:5.902328968048096, Rollout: 1[0m
[32mVal -- Epoch:120, loss:5.925111293792725, Rollout: 1[0m
[32mVal -- Epoch:120, loss:5.912844657897949, Rollout: 1[0m
[32mVal -- Epoch:120, loss:6.0405592918396, Rollout: 1[0m
[32mVal -- Epoch:120, loss:5.89017915725708, Rollout: 1[0m
[32mVal -- Epoch:120, loss:5.8962016105651855, Rollout: 1[0m
[32mVal -- Epoch:120, loss:5.887435436248779, Rollout: 1[0m
Validation completed in 0.2427634636561076 mins, Total time: 170.5765119989713 mins
Training epoch completed in 1.3537252267201743 mins, Total time: 171.93026250600815 mins
Train -- Epoch:121, loss:5.875586986541748, Rollout:30
Training epoch completed in 1.3579656998316447 mins, Total time: 173.28823008934657 mins
Training epoch completed in 1.3035030047098795 mins, Total time: 174.5917343179385 mins
Training epoch completed in 1.312593658765157 mins, Total time: 175.90432989994684 mins
Train -- Epoch:124, loss:5.893867492675781, Rollout:30
Training epoch completed in 1.2822083870569865 mins, Total time: 177.18653947909672 mins
[32mVal -- Epoch:125, loss:5.878063201904297, Rollout: 10[0m
[32mVal -- Epoch:125, loss:5.897047996520996, Rollout: 10[0m
[32mVal -- Epoch:125, loss:5.924661159515381, Rollout: 10[0m
[32mVal -- Epoch:125, loss:5.907896041870117, Rollout: 10[0m
[32mVal -- Epoch:125, loss:6.038067817687988, Rollout: 10[0m
[32mVal -- Epoch:125, loss:5.880324840545654, Rollout: 10[0m
[32mVal -- Epoch:125, loss:5.891221046447754, Rollout: 10[0m
[32mVal -- Epoch:125, loss:5.885630130767822, Rollout: 10[0m
Validation completed in 0.20775255759557087 mins, Total time: 177.39429391622542 mins
Training epoch completed in 1.3293095032374065 mins, Total time: 178.72360411087672 mins
Train -- Epoch:126, loss:5.899686813354492, Rollout:30
Training epoch completed in 1.3205140709877015 mins, Total time: 180.04412014484404 mins
Training epoch completed in 1.4124419967333475 mins, Total time: 181.4565638621648 mins
Training epoch completed in 1.323468844095866 mins, Total time: 182.78003462553025 mins
Train -- Epoch:129, loss:5.849125862121582, Rollout:30
Training epoch completed in 1.320311176776886 mins, Total time: 184.10034788846968 mins
[32mVal -- Epoch:130, loss:5.88134241104126, Rollout: 10[0m
[32mVal -- Epoch:130, loss:5.898846626281738, Rollout: 10[0m
[32mVal -- Epoch:130, loss:5.92409086227417, Rollout: 10[0m
[32mVal -- Epoch:130, loss:5.911927700042725, Rollout: 10[0m
[32mVal -- Epoch:130, loss:6.0389509201049805, Rollout: 10[0m
[32mVal -- Epoch:130, loss:5.882493495941162, Rollout: 10[0m
[32mVal -- Epoch:130, loss:5.892649173736572, Rollout: 10[0m
[32mVal -- Epoch:130, loss:5.8811821937561035, Rollout: 10[0m
Validation completed in 0.2270695169766744 mins, Total time: 184.3274184902509 mins
Training epoch completed in 1.31351611216863 mins, Total time: 185.64093528588612 mins
Train -- Epoch:131, loss:5.855550289154053, Rollout:30
Training epoch completed in 1.2835853179295857 mins, Total time: 186.92452272574107 mins
Training epoch completed in 1.273822271823883 mins, Total time: 188.19834669033688 mins
Train -- Epoch:133, loss:5.851942539215088, Rollout:30
Training epoch completed in 1.3003483891487122 mins, Total time: 189.49869819879532 mins
Training epoch completed in 1.3241111556688945 mins, Total time: 190.82281149625777 mins
[32mVal -- Epoch:135, loss:5.881679534912109, Rollout: 10[0m
[32mVal -- Epoch:135, loss:5.89733362197876, Rollout: 10[0m
[32mVal -- Epoch:135, loss:5.92503547668457, Rollout: 10[0m
[32mVal -- Epoch:135, loss:5.9086713790893555, Rollout: 10[0m
[32mVal -- Epoch:135, loss:6.039933204650879, Rollout: 10[0m
[32mVal -- Epoch:135, loss:5.881497859954834, Rollout: 10[0m
[32mVal -- Epoch:135, loss:5.892737865447998, Rollout: 10[0m
[32mVal -- Epoch:135, loss:5.8907880783081055, Rollout: 10[0m
Validation completed in 0.20700418949127197 mins, Total time: 191.02981734275818 mins
Training epoch completed in 1.3363582054773966 mins, Total time: 192.36617626349133 mins
Train -- Epoch:136, loss:5.875441551208496, Rollout:30
Training epoch completed in 1.335814360777537 mins, Total time: 193.70199252367019 mins
Training epoch completed in 1.3185380220413208 mins, Total time: 195.02053234974542 mins
Train -- Epoch:138, loss:5.83894157409668, Rollout:30
Training epoch completed in 1.3131869157155356 mins, Total time: 196.3337204535802 mins
Training epoch completed in 1.325508213043213 mins, Total time: 197.65922962029774 mins
[32mVal -- Epoch:140, loss:5.878360748291016, Rollout: 10[0m
[32mVal -- Epoch:140, loss:5.899673938751221, Rollout: 10[0m
[32mVal -- Epoch:140, loss:5.925821781158447, Rollout: 10[0m
[32mVal -- Epoch:140, loss:5.907357692718506, Rollout: 10[0m
[32mVal -- Epoch:140, loss:6.04032564163208, Rollout: 10[0m
[32mVal -- Epoch:140, loss:5.88063383102417, Rollout: 10[0m
[32mVal -- Epoch:140, loss:5.893727779388428, Rollout: 10[0m
[32mVal -- Epoch:140, loss:5.890066623687744, Rollout: 10[0m
Validation completed in 0.19623512029647827 mins, Total time: 197.85546576976776 mins
Training epoch completed in 1.3649451375007629 mins, Total time: 199.22041260004045 mins
Train -- Epoch:141, loss:5.84847354888916, Rollout:30
Training epoch completed in 1.3141756693522135 mins, Total time: 200.53459003369014 mins
Training epoch completed in 1.2854357957839966 mins, Total time: 201.8200274348259 mins
Train -- Epoch:143, loss:5.908506393432617, Rollout:30
Training epoch completed in 1.4112253506978354 mins, Total time: 203.23125464518864 mins
Training epoch completed in 1.3759165048599242 mins, Total time: 204.60717223882676 mins
[32mVal -- Epoch:145, loss:5.8805413246154785, Rollout: 10[0m
[32mVal -- Epoch:145, loss:5.897756576538086, Rollout: 10[0m
[32mVal -- Epoch:145, loss:5.927252292633057, Rollout: 10[0m
[32mVal -- Epoch:145, loss:5.906259059906006, Rollout: 10[0m
[32mVal -- Epoch:145, loss:6.037578582763672, Rollout: 10[0m
[32mVal -- Epoch:145, loss:5.8802337646484375, Rollout: 10[0m
[32mVal -- Epoch:145, loss:5.890761852264404, Rollout: 10[0m
[32mVal -- Epoch:145, loss:5.889267444610596, Rollout: 10[0m
Validation completed in 0.19234418471654255 mins, Total time: 204.79951751232147 mins
Training epoch completed in 1.338670837879181 mins, Total time: 206.13818948268892 mins
Train -- Epoch:146, loss:5.87240743637085, Rollout:30
Training epoch completed in 1.3838616887728372 mins, Total time: 207.52205276091894 mins
Training epoch completed in 1.3328923066457112 mins, Total time: 208.85494666496913 mins
Train -- Epoch:148, loss:5.87678337097168, Rollout:30
Training epoch completed in 1.3035069902737935 mins, Total time: 210.15845544735592 mins
Training epoch completed in 1.4044354756673176 mins, Total time: 211.56289199988046 mins
[32mVal -- Epoch:150, loss:5.8800129890441895, Rollout: 10[0m
[32mVal -- Epoch:150, loss:5.8986592292785645, Rollout: 10[0m
[32mVal -- Epoch:150, loss:5.926027297973633, Rollout: 10[0m
[32mVal -- Epoch:150, loss:5.907386779785156, Rollout: 10[0m
[32mVal -- Epoch:150, loss:6.040001392364502, Rollout: 10[0m
[32mVal -- Epoch:150, loss:5.883277893066406, Rollout: 10[0m
[32mVal -- Epoch:150, loss:5.894652843475342, Rollout: 10[0m
[32mVal -- Epoch:150, loss:5.890963077545166, Rollout: 10[0m
Validation completed in 0.2729550838470459 mins, Total time: 211.83584965467452 mins
Training epoch completed in 1.3074134866396585 mins, Total time: 213.1432639757792 mins
Train -- Epoch:151, loss:5.920722007751465, Rollout:30
Training epoch completed in 1.364534842967987 mins, Total time: 214.50780065457027 mins
Training epoch completed in 1.3716715017954508 mins, Total time: 215.8794733842214 mins
Train -- Epoch:153, loss:5.857773780822754, Rollout:30
Training epoch completed in 1.361302375793457 mins, Total time: 217.24077815612156 mins
Training epoch completed in 1.3584662834803263 mins, Total time: 218.59924656947453 mins
[32mVal -- Epoch:155, loss:5.8856282234191895, Rollout: 10[0m
[32mVal -- Epoch:155, loss:5.901318550109863, Rollout: 10[0m
[32mVal -- Epoch:155, loss:5.925610542297363, Rollout: 10[0m
[32mVal -- Epoch:155, loss:5.911887168884277, Rollout: 10[0m
[32mVal -- Epoch:155, loss:6.0394206047058105, Rollout: 10[0m
[32mVal -- Epoch:155, loss:5.886230945587158, Rollout: 10[0m
[32mVal -- Epoch:155, loss:5.897355079650879, Rollout: 10[0m
[32mVal -- Epoch:155, loss:5.891426086425781, Rollout: 10[0m
Validation completed in 0.22740880648295084 mins, Total time: 218.826657640934 mins
Training epoch completed in 1.3485667943954467 mins, Total time: 220.17522542476655 mins
Train -- Epoch:156, loss:5.88490104675293, Rollout:30
Training epoch completed in 1.3915807048479716 mins, Total time: 221.56681060791016 mins
Training epoch completed in 1.3329853415489197 mins, Total time: 222.8997970779737 mins
Train -- Epoch:158, loss:5.848321437835693, Rollout:30
Training epoch completed in 1.3340229113896689 mins, Total time: 224.23382115364075 mins
Training epoch completed in 1.3577584425608318 mins, Total time: 225.59158168633778 mins
[32mVal -- Epoch:160, loss:5.886051177978516, Rollout: 10[0m
[32mVal -- Epoch:160, loss:5.8990397453308105, Rollout: 10[0m
[32mVal -- Epoch:160, loss:5.927701950073242, Rollout: 10[0m
[32mVal -- Epoch:160, loss:5.911798477172852, Rollout: 10[0m
[32mVal -- Epoch:160, loss:6.046941757202148, Rollout: 10[0m
[32mVal -- Epoch:160, loss:5.883605480194092, Rollout: 10[0m
[32mVal -- Epoch:160, loss:5.8907904624938965, Rollout: 10[0m
[32mVal -- Epoch:160, loss:5.890735149383545, Rollout: 10[0m
Validation completed in 0.23424137433369954 mins, Total time: 225.82582468589146 mins
Training epoch completed in 1.3576515515645344 mins, Total time: 227.1835035363833 mins
Train -- Epoch:161, loss:5.852726459503174, Rollout:30
Training epoch completed in 1.3358818332354228 mins, Total time: 228.5193865140279 mins
Training epoch completed in 1.3526996493339538 mins, Total time: 229.87208778858184 mins
Train -- Epoch:163, loss:5.860960006713867, Rollout:30
Training epoch completed in 1.402433411280314 mins, Total time: 231.27452296415964 mins
